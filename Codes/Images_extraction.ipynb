{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Wnviq5bJF2-k","executionInfo":{"status":"ok","timestamp":1761992099767,"user_tz":-330,"elapsed":53544,"user":{"displayName":"Bansiben Mahkana","userId":"07208300408829029445"}},"outputId":"21201780-7050-4542-ce90-8165bc3ab367"},"outputs":[{"output_type":"stream","name":"stdout","text":["✅ All A172 images copied to: /content/drive/MyDrive/DIP_Grp_5/LIVECell_dataset_2021/annotations/LIVECell/A172_images\n"]}],"source":["import os\n","import shutil\n","\n","# --- Input paths ---\n","source_folder = \"/content/drive/MyDrive/DIP_Grp_5/LIVECell_dataset_2021/annotations/LIVECell/livecell_coco_train_converted_tif\"         # Folder with all images\n","destination_folder = \"/content/drive/MyDrive/DIP_Grp_5/LIVECell_dataset_2021/annotations/LIVECell/A172_images\"    # Folder to save BV2 images\n","cell_type = \"A172\"                             # Cell type to extract\n","\n","# --- Create destination folder if it doesn't exist ---\n","os.makedirs(destination_folder, exist_ok=True)\n","\n","# --- Loop through files and copy only BV2 images ---\n","for filename in os.listdir(source_folder):\n","    if filename.startswith(cell_type):  # Check if image belongs to given cell type\n","        src = os.path.join(source_folder, filename)\n","        dst = os.path.join(destination_folder, filename)\n","        shutil.copy(src, dst)\n","\n","print(f\"✅ All {cell_type} images copied to: {destination_folder}\")\n"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"chlWCqz_wiYJ","executionInfo":{"status":"ok","timestamp":1761989655901,"user_tz":-330,"elapsed":9487,"user":{"displayName":"Bansiben Mahkana","userId":"07208300408829029445"}},"outputId":"635a2418-f4e3-45ef-a8e6-5e1eef1df6a1"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["import cv2\n","import numpy as np\n","from sklearn.metrics import confusion_matrix\n","\n","# --- Paths to your images ---\n","ground_truth_path = \"/path/to/ground_truth.tif\"\n","predicted_path = \"/path/to/predicted_mask.tif\"\n","\n","# --- Read images as grayscale ---\n","gt = cv2.imread(ground_truth_path, cv2.IMREAD_GRAYSCALE)\n","pred = cv2.imread(predicted_path, cv2.IMREAD_GRAYSCALE)\n","\n","# --- Resize predicted if needed ---\n","if gt.shape != pred.shape:\n","    pred = cv2.resize(pred, (gt.shape[1], gt.shape[0]))\n","\n","# --- Binarize both images (0 and 1) ---\n","_, gt_bin = cv2.threshold(gt, 127, 1, cv2.THRESH_BINARY)\n","_, pred_bin = cv2.threshold(pred, 127, 1, cv2.THRESH_BINARY)\n","\n","# --- Flatten for metric calculation ---\n","gt_flat = gt_bin.flatten()\n","pred_flat = pred_bin.flatten()\n","\n","# --- Confusion Matrix ---\n","tn, fp, fn, tp = confusion_matrix(gt_flat, pred_flat).ravel()\n","\n","# --- Metrics ---\n","accuracy = (tp + tn) / (tp + tn + fp + fn)\n","precision = tp / (tp + fp + 1e-8)\n","recall = tp / (tp + fn + 1e-8)\n","f1_score = 2 * precision * recall / (precision + recall + 1e-8)\n","iou = tp / (tp + fp + fn + 1e-8)\n","dice = (2 * tp) / (2 * tp + fp + fn + 1e-8)\n","\n","print(\"✅ Segmentation Performance Metrics:\")\n","print(f\"Accuracy   : {accuracy * 100:.2f}%\")\n","print(f\"Precision  : {precision * 100:.2f}%\")\n","print(f\"Recall     : {recall * 100:.2f}%\")\n","print(f\"F1-score   : {f1_score * 100:.2f}%\")\n","print(f\"IoU (Jaccard): {iou * 100:.2f}%\")\n","print(f\"Dice Coefficient: {dice * 100:.2f}%\")\n"],"metadata":{"id":"76XWTQsJJ5zb"},"execution_count":null,"outputs":[]}]}